import openai
from dotenv import load_dotenv
import os
from requests import get, post

load_dotenv()
OpenAiKey = os.getenv("OpenAiKey")
openai.api_key = OpenAiKey


def generate_prediction(water_state, location):
    """Generates a prediction based on the data given by the senson in the past hour.
    Returns the prediction"""

    prompt = f"""
    You are in the role of an oceanographer specializing in marine ecology and
    environmental monitoring. You have expertise in various aspects of
    oceanography including water measurements such as turbidity, salinity,
    temperature, and noise level. Additionally you are specializing also in
    marine wildlife and their interactions with their environment.
    Now a huge metal container is deployed underwater. It is located 40 meters from the coast
    and within 40 meters of depth. That container contains a datacenter,
    in itself. When the data center is used, it generates heat. In order for this to be
    an environmentally safe and friendly technology, there is a device which floats around 
    the container. It contains a water turbidity sensor, water salinity sensor, temperature sensor,
    and noise level sensor. The container is located at {location}
    Based on your professional background and the data recorded by the device
    you are asked to generate an statement which describes is the current
    water state safe and normal or there is risk for the oceans and the wildlife.
    Here is more information for data and the sensors:
    Each sensor has a different range of values which is measured in Volts.
    You'll need to convert the recorded data to a value which is measured in the specific unit.
    For reference the lowest value can be 0V and the highest value can be 3.3V

    Water turbidity sensor - photoresistor(LDR) and LED
    Water salinity sensor - HW-038
    Temperature sensor - DHT22 
    We can't allow temperature values outside of  0.99V to 1.32V.
    Noise level sensor - KY-038

    The recorded data is as follows:
    {water_state}

    At the end, without displaying compare the orginal data after it is convered from Volts 
    to the right corresponding unit to the expected values for the units in the specific location.
    Display only the statement that is generated by the model, statrting with Type:
    Safe or Risk(with the metric(s) that are not safe).
    If any of the value is outside of the allowed error margin, emidiately show an risk message that there
    is a problem else explain why everything is fine.
    
    """
    try:
        # Generate the response
        response = openai.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "system", "content": prompt}],
            temperature=0.2
        )
        # Extract the completion text
        
        statement = response.choices[0].message.content
        return statement
    except Exception as e:
        return f"An error occurred: {e}"


data_response = get('http://192.168.166.172:8000' + '/api/device/1',
        headers={'Authorization': f"Bearer 1|QxgMeCdh0gPN5anMGBmzXEWaVxRTereN3NjWUWIj9dd1cd74"})

location = "Black sea"
print(data_response.content.decode('utf-8'))
prediction = generate_prediction(data_response, location)


print(prediction)